{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZwH2ifWEYEfJ",
    "outputId": "5d048042-ceef-4bd3-f299-03d12727c8bd"
   },
   "outputs": [],
   "source": [
    "# # Use GFPGAN folder from drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# drive_path = '/content/drive/MyDrive/GFPColab';\n",
    "# # %mkdir -p $drive_path\n",
    "# # %cp -r ../GFPGAN $drive_path\n",
    "# %cd $drive_path/GFPGAN\n",
    "\n",
    "# # %env BASICSR_JIT=True\n",
    "# %env BASICSR_EXT=True\n",
    "\n",
    "# # Clone GFPGAN and enter the GFPGAN folder\n",
    "# # %cd /content\n",
    "# # !rm -rf GFPGAN\n",
    "# # !git clone https://github.com/TencentARC/GFPGAN.git\n",
    "# # %cd GFPGAN\n",
    "\n",
    "# # Set up the environment\n",
    "# # Install basicsr - https://github.com/xinntao/BasicSR\n",
    "# # We use BasicSR for both training and inference\n",
    "# !pip install basicsr\n",
    "# # Install facexlib - https://github.com/xinntao/facexlib\n",
    "# # We use face detection and face restoration helper in the facexlib package\n",
    "# !pip install facexlib\n",
    "# # Install other depencencies\n",
    "# !pip install -r requirements.txt\n",
    "# !python setup.py develop\n",
    "# !pip install realesrgan  # used for enhancing the background (non-face) regions\n",
    "# # Download the pre-trained model\n",
    "# # !wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo\n",
      "/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo\r\n"
     ]
    }
   ],
   "source": [
    "%cd repo\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7cDFF2w3kfM"
   },
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cR0FoHalqdgY"
   },
   "outputs": [],
   "source": [
    "# !BASICSR_JIT=True BASICSR_EXT=True pip install basicsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mWn0WLhD3jrr"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from gfpgan.archs.gfpganv1_arch import GFPGANv1\n",
    "\n",
    "# gfpgan = GFPGANv1(\n",
    "#                 out_size=512,\n",
    "#                 num_style_feat=512,\n",
    "#                 channel_multiplier=1,\n",
    "#                 decoder_load_path=None,\n",
    "#                 fix_decoder=True,\n",
    "#                 num_mlp=8,\n",
    "#                 input_is_latent=True,\n",
    "#                 different_w=True,\n",
    "#                 narrow=1,\n",
    "#                 sft_half=True)\n",
    "# model_path = 'experiments/pretrained_models/GFPGANv1.pth'\n",
    "# loadnet = torch.load(model_path)\n",
    "# if 'params_ema' in loadnet:\n",
    "#     keyname = 'params_ema'\n",
    "# else:\n",
    "#     keyname = 'params'\n",
    "# gfpgan.load_state_dict(loadnet[keyname], strict=True)\n",
    "\n",
    "# gfpgan.eval()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTnCRBWRZFoW",
    "outputId": "0c81688b-f0a1-4993-e530-ce3adb393fcf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/venv2/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo {'opt': 'options/my_train_gfpgan_v1.yml', 'launcher': 'none', 'auto_resume': False, 'debug': False, 'local_rank': 0, 'force_yml': None}\n",
      "Disable distributed.\n",
      "OrderedDict([('name', 'train_GFPGANv1_512'), ('model_type', 'GFPGANModel'), ('num_gpu', 1), ('manual_seed', 0), ('datasets', OrderedDict([('train', OrderedDict([('name', 'FFHQ'), ('type', 'FFHQDegradationDataset'), ('dataroot_gt', 'datasets/images_gt'), ('io_backend', OrderedDict([('type', 'disk')])), ('use_hflip', True), ('mean', [0.5, 0.5, 0.5]), ('std', [0.5, 0.5, 0.5]), ('out_size', 512), ('blur_kernel_size', 41), ('kernel_list', ['iso', 'aniso']), ('kernel_prob', [0.5, 0.5]), ('blur_sigma', [0.1, 10]), ('downsample_range', [0.8, 8]), ('noise_range', [0, 20]), ('jpeg_range', [60, 100]), ('color_jitter_prob', 0.3), ('color_jitter_shift', 20), ('color_jitter_pt_prob', 0.3), ('gray_prob', 0.01), ('crop_components', True), ('component_path', 'experiments/pretrained_models/FFHQ_eye_mouth_landmarks_512.pth'), ('eye_enlarge_ratio', 1.4), ('use_shuffle', False), ('num_worker_per_gpu', 6), ('batch_size_per_gpu', 8), ('dataset_enlarge_ratio', 1), ('prefetch_mode', None), ('phase', 'train')]))])), ('network_g', OrderedDict([('type', 'GFPGANv1'), ('out_size', 512), ('num_style_feat', 512), ('channel_multiplier', 1), ('resample_kernel', [1, 3, 3, 1]), ('decoder_load_path', 'experiments/pretrained_models/StyleGAN2_512_Cmul1_FFHQ_B12G4_scratch_800k.pth'), ('fix_decoder', True), ('num_mlp', 8), ('lr_mlp', 0.01), ('input_is_latent', True), ('different_w', True), ('narrow', 1), ('sft_half', True)])), ('network_d', OrderedDict([('type', 'StyleGAN2Discriminator'), ('out_size', 512), ('channel_multiplier', 1), ('resample_kernel', [1, 3, 3, 1])])), ('network_d_left_eye', OrderedDict([('type', 'FacialComponentDiscriminator')])), ('network_d_right_eye', OrderedDict([('type', 'FacialComponentDiscriminator')])), ('network_d_mouth', OrderedDict([('type', 'FacialComponentDiscriminator')])), ('network_identity', OrderedDict([('type', 'ResNetArcFace'), ('block', 'IRBlock'), ('layers', [2, 2, 2, 2]), ('use_se', False)])), ('path', OrderedDict([('pretrain_network_g', 'experiments/pretrained_models/GFPGANv1.pth'), ('param_key_g', 'params_ema'), ('strict_load_g', None), ('pretrain_network_d', 'experiments/pretrained_models/GFPGANv1_net_d.pth'), ('pretrain_network_d_left_eye', 'experiments/pretrained_models/GFPGANv1_net_d_left_eye.pth'), ('pretrain_network_d_right_eye', 'experiments/pretrained_models/GFPGANv1_net_d_right_eye.pth'), ('pretrain_network_d_mouth', 'experiments/pretrained_models/GFPGANv1_net_d_mouth.pth'), ('pretrain_network_identity', 'experiments/pretrained_models/arcface_resnet18.pth'), ('resume_state', None), ('ignore_resume_networks', ['network_identity']), ('experiments_root', '/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512'), ('models', '/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512/models'), ('training_states', '/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512/training_states'), ('log', '/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512'), ('visualization', '/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512/visualization')])), ('train', OrderedDict([('optim_g', OrderedDict([('type', 'Adam'), ('lr', 0.002)])), ('optim_d', OrderedDict([('type', 'Adam'), ('lr', 0.002)])), ('optim_component', OrderedDict([('type', 'Adam'), ('lr', 0.002)])), ('scheduler', OrderedDict([('type', 'MultiStepLR'), ('milestones', [600000, 700000]), ('gamma', 0.5)])), ('total_iter', 50000), ('warmup_iter', -1), ('pixel_opt', OrderedDict([('type', 'L1Loss'), ('loss_weight', 0.1), ('reduction', 'mean')])), ('L1_opt', OrderedDict([('type', 'L1Loss'), ('loss_weight', 1), ('reduction', 'mean')])), ('pyramid_loss_weight', 1), ('remove_pyramid_loss', 50000), ('perceptual_opt', OrderedDict([('type', 'PerceptualLoss'), ('layer_weights', OrderedDict([('conv1_2', 0.1), ('conv2_2', 0.1), ('conv3_4', 1), ('conv4_4', 1), ('conv5_4', 1)])), ('vgg_type', 'vgg19'), ('use_input_norm', True), ('perceptual_weight', 1.0), ('style_weight', 50), ('range_norm', True), ('criterion', 'l1')])), ('gan_opt', OrderedDict([('type', 'GANLoss'), ('gan_type', 'wgan_softplus'), ('loss_weight', 0.1)])), ('r1_reg_weight', 10), ('gan_component_opt', OrderedDict([('type', 'GANLoss'), ('gan_type', 'vanilla'), ('real_label_val', 1.0), ('fake_label_val', 0.0), ('loss_weight', 1.0)])), ('comp_style_weight', 200), ('identity_weight', 10), ('net_d_iters', 1), ('net_d_init_iters', 0), ('net_d_reg_every', 16)])), ('val', OrderedDict([('val_freq', 5000.0), ('save_img', True), ('metrics', OrderedDict([('psnr', OrderedDict([('type', 'calculate_psnr'), ('crop_border', 0), ('test_y_channel', False)]))]))])), ('logger', OrderedDict([('print_freq', 1000), ('save_checkpoint_freq', 5000.0), ('use_tb_logger', True), ('wandb', OrderedDict([('project', None), ('resume_id', None)]))])), ('dist_params', OrderedDict([('backend', 'nccl'), ('port', 29500)])), ('find_unused_parameters', True), ('dist', False), ('rank', 0), ('world_size', 1), ('auto_resume', False), ('is_train', True)])\n"
     ]
    }
   ],
   "source": [
    "from gfpgan.my_options_parser import my_parse_options\n",
    "\n",
    "args = {}\n",
    "args['opt'] = 'options/my_train_gfpgan_v1.yml'\n",
    "args['launcher'] = 'none'\n",
    "args['auto_resume'] = False\n",
    "args['debug'] = False\n",
    "args['local_rank'] = 0\n",
    "args['force_yml'] = None\n",
    "root_path = '/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo'\n",
    "opt_file = 'options/my_train_gfpgan_v1.yml'\n",
    "opt, args = my_parse_options(root_path, args)\n",
    "\n",
    "print(opt)\n",
    "opt['root_path'] = root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_zNnGIt8k3iP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "from os import path as osp\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from basicsr.train import load_resume_state, init_tb_loggers\n",
    "# from basicsr.train import create_train_val_dataloader\n",
    "\n",
    "\n",
    "from basicsr.data import build_dataloader, build_dataset\n",
    "from basicsr.data.prefetch_dataloader import CPUPrefetcher, CUDAPrefetcher\n",
    "from basicsr.models import build_model\n",
    "from basicsr.utils import (AvgTimer, MessageLogger, check_resume, get_env_info, get_root_logger, get_time_str,\n",
    "                           init_tb_logger, init_wandb_logger, make_exp_dirs, mkdir_and_rename, scandir)\n",
    "from basicsr.utils.options import copy_opt_file, dict2str, parse_options\n",
    "from functools import partial\n",
    "\n",
    "from basicsr.utils.dist_util import get_dist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2TXKjn8JmxzJ"
   },
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id, num_workers, rank, seed):\n",
    "    # Set the worker seed to num_workers * rank + worker_id + seed\n",
    "    worker_seed = num_workers * rank + worker_id + seed\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def build_dataloader(dataset, dataset_opt, num_gpu=1, dist=False, sampler=None, seed=None, batch_sampler=None):\n",
    "    \"\"\"Build dataloader.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): Dataset.\n",
    "        dataset_opt (dict): Dataset options. It contains the following keys:\n",
    "            phase (str): 'train' or 'val'.\n",
    "            num_worker_per_gpu (int): Number of workers for each GPU.\n",
    "            batch_size_per_gpu (int): Training batch size for each GPU.\n",
    "        num_gpu (int): Number of GPUs. Used only in the train phase.\n",
    "            Default: 1.\n",
    "        dist (bool): Whether in distributed training. Used only in the train\n",
    "            phase. Default: False.\n",
    "        sampler (torch.utils.data.sampler): Data sampler. Default: None.\n",
    "        seed (int | None): Seed. Default: None\n",
    "    \"\"\"\n",
    "    phase = dataset_opt['phase']\n",
    "    rank, _ = get_dist_info()\n",
    "    if phase == 'train':\n",
    "        if dist:  # distributed training\n",
    "            batch_size = dataset_opt['batch_size_per_gpu']\n",
    "            num_workers = dataset_opt['num_worker_per_gpu']\n",
    "        else:  # non-distributed training\n",
    "            multiplier = 1 if num_gpu == 0 else num_gpu\n",
    "            batch_size = dataset_opt['batch_size_per_gpu'] * multiplier\n",
    "            num_workers = dataset_opt['num_worker_per_gpu'] * multiplier\n",
    "        dataloader_args = dict(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            sampler=sampler,\n",
    "            drop_last=True)\n",
    "        if batch_sampler is not None:\n",
    "          dataloader_args = dict(\n",
    "            dataset=dataset,\n",
    "            num_workers=num_workers,\n",
    "            batch_sampler=batch_sampler)\n",
    "        # if sampler is None:\n",
    "        #     dataloader_args['shuffle'] = True\n",
    "        dataloader_args['worker_init_fn'] = partial(\n",
    "            worker_init_fn, num_workers=num_workers, rank=rank, seed=seed) if seed is not None else None\n",
    "    elif phase in ['val', 'test']:  # validation\n",
    "        dataloader_args = dict(dataset=dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    else:\n",
    "        raise ValueError(f'Wrong dataset phase: {phase}. ' \"Supported ones are 'train', 'val' and 'test'.\")\n",
    "\n",
    "    dataloader_args['pin_memory'] = dataset_opt.get('pin_memory', False)\n",
    "    dataloader_args['persistent_workers'] = dataset_opt.get('persistent_workers', False)\n",
    "\n",
    "    prefetch_mode = dataset_opt.get('prefetch_mode')\n",
    "    if prefetch_mode == 'cpu':  # CPUPrefetcher\n",
    "        num_prefetch_queue = dataset_opt.get('num_prefetch_queue', 1)\n",
    "        logger = get_root_logger()\n",
    "        logger.info(f'Use {prefetch_mode} prefetch dataloader: num_prefetch_queue = {num_prefetch_queue}')\n",
    "        return PrefetchDataLoader(num_prefetch_queue=num_prefetch_queue, **dataloader_args)\n",
    "    else:\n",
    "        # prefetch_mode=None: Normal dataloader\n",
    "        # prefetch_mode='cuda': dataloader for CUDAPrefetcher\n",
    "        return torch.utils.data.DataLoader(**dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZZdRnqP-pBdW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "\n",
    "class EnlargedSampler(Sampler):\n",
    "    \"\"\"Sampler that restricts data loading to a subset of the dataset.\n",
    "\n",
    "    Modified from torch.utils.data.distributed.DistributedSampler\n",
    "    Support enlarging the dataset for iteration-based training, for saving\n",
    "    time when restart the dataloader after each epoch\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): Dataset used for sampling.\n",
    "        num_replicas (int | None): Number of processes participating in\n",
    "            the training. It is usually the world_size.\n",
    "        rank (int | None): Rank of the current process within num_replicas.\n",
    "        ratio (int): Enlarging ratio. Default: 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, num_replicas, rank, ratio=1, batch_size=3):\n",
    "        self.dataset = dataset\n",
    "        self.num_replicas = num_replicas\n",
    "        self.rank = rank\n",
    "        self.epoch = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = math.ceil(len(self.dataset) * ratio / self.num_replicas)\n",
    "        self.total_size = self.num_samples * self.num_replicas\n",
    "        self.batch_indices = []\n",
    "        for batch in self.dataset.batch_paths:\n",
    "          batch_index = []\n",
    "          for id in batch:\n",
    "            if len(batch_index) >= self.batch_size:\n",
    "              self.batch_indices.append(batch_index)\n",
    "              batch_index = []\n",
    "            batch_index.append(id)\n",
    "        print('======================= BATCH SIZE')\n",
    "        print(self.batch_size)\n",
    "#         print(self.batch_indices)\n",
    "        \n",
    "\n",
    "    def __iter__(self):\n",
    "        # print(self.dataset.batch_paths)\n",
    "        return iter(self.batch_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dclEaNBMjcmA"
   },
   "outputs": [],
   "source": [
    "# code for the loader\n",
    "\n",
    "def create_train_val_dataloader(opt, logger):\n",
    "    # create train and val dataloaders\n",
    "    train_loader, val_loaders = None, []\n",
    "    for phase, dataset_opt in opt['datasets'].items():\n",
    "        if phase == 'train':\n",
    "            dataset_enlarge_ratio = dataset_opt.get('dataset_enlarge_ratio', 1)\n",
    "            train_set = build_dataset(dataset_opt)\n",
    "            train_sampler = EnlargedSampler(train_set, opt['world_size'], opt['rank'], dataset_enlarge_ratio, batch_size=dataset_opt['batch_size_per_gpu'])\n",
    "            train_loader = build_dataloader(\n",
    "                train_set,\n",
    "                dataset_opt,\n",
    "                num_gpu=opt['num_gpu'],\n",
    "                dist=opt['dist'],\n",
    "                batch_sampler=train_sampler,\n",
    "                seed=opt['manual_seed'])\n",
    "\n",
    "            num_iter_per_epoch = math.ceil(\n",
    "                len(train_set) * dataset_enlarge_ratio / (dataset_opt['batch_size_per_gpu'] * opt['world_size']))\n",
    "            total_iters = int(opt['train']['total_iter'])\n",
    "            total_epochs = math.ceil(total_iters / (num_iter_per_epoch))\n",
    "            logger.info('Training statistics:'\n",
    "                        f'\\n\\tNumber of train images: {len(train_set)}'\n",
    "                        f'\\n\\tDataset enlarge ratio: {dataset_enlarge_ratio}'\n",
    "                        f'\\n\\tBatch size per gpu: {dataset_opt[\"batch_size_per_gpu\"]}'\n",
    "                        f'\\n\\tWorld size (gpu number): {opt[\"world_size\"]}'\n",
    "                        f'\\n\\tRequire iter number per epoch: {num_iter_per_epoch}'\n",
    "                        f'\\n\\tTotal epochs: {total_epochs}; iters: {total_iters}.')\n",
    "        elif phase.split('_')[0] == 'val':\n",
    "            val_set = build_dataset(dataset_opt)\n",
    "            val_loader = build_dataloader(\n",
    "                val_set, dataset_opt, num_gpu=opt['num_gpu'], dist=opt['dist'], sampler=None, seed=opt['manual_seed'])\n",
    "            logger.info(f'Number of val images/folders in {dataset_opt[\"name\"]}: {len(val_set)}')\n",
    "            val_loaders.append(val_loader)\n",
    "        else:\n",
    "            raise ValueError(f'Dataset phase {phase} is not recognized.')\n",
    "\n",
    "    return train_loader, train_sampler, val_loaders, total_epochs, total_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PR9ltG8ej2O2",
    "outputId": "16048dc6-2d84-4ac6-edef-498d82c7717a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path already exists. Rename it to /media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/tb_logger/train_GFPGANv1_512_archived_20220502_150623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:06:23,036 INFO: \n",
      "                ____                _       _____  ____\n",
      "               / __ ) ____ _ _____ (_)_____/ ___/ / __ \\\n",
      "              / __  |/ __ `// ___// // ___/\\__ \\ / /_/ /\n",
      "             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/\n",
      "            /_____/ \\__,_//____//_/ \\___//____//_/ |_|\n",
      "     ______                   __   __                 __      __\n",
      "    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /\n",
      "   / / __ / __ \\ / __ \\ / __  /  / /   / / / // ___// //_/  / /\n",
      "  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/\n",
      "  \\____/ \\____/ \\____/ \\____/  /_____/\\____/ \\___//_/|_|  (_)\n",
      "    \n",
      "Version Information: \n",
      "\tBasicSR: 1.3.5\n",
      "\tPyTorch: 1.11.0+cu102\n",
      "\tTorchVision: 0.12.0+cu102\n",
      "2022-05-02 15:06:23,037 INFO: \n",
      "  name: train_GFPGANv1_512\n",
      "  model_type: GFPGANModel\n",
      "  num_gpu: 1\n",
      "  manual_seed: 0\n",
      "  datasets:[\n",
      "    train:[\n",
      "      name: FFHQ\n",
      "      type: FFHQDegradationDataset\n",
      "      dataroot_gt: datasets/images_gt\n",
      "      io_backend:[\n",
      "        type: disk\n",
      "      ]\n",
      "      use_hflip: True\n",
      "      mean: [0.5, 0.5, 0.5]\n",
      "      std: [0.5, 0.5, 0.5]\n",
      "      out_size: 512\n",
      "      blur_kernel_size: 41\n",
      "      kernel_list: ['iso', 'aniso']\n",
      "      kernel_prob: [0.5, 0.5]\n",
      "      blur_sigma: [0.1, 10]\n",
      "      downsample_range: [0.8, 8]\n",
      "      noise_range: [0, 20]\n",
      "      jpeg_range: [60, 100]\n",
      "      color_jitter_prob: 0.3\n",
      "      color_jitter_shift: 20\n",
      "      color_jitter_pt_prob: 0.3\n",
      "      gray_prob: 0.01\n",
      "      crop_components: True\n",
      "      component_path: experiments/pretrained_models/FFHQ_eye_mouth_landmarks_512.pth\n",
      "      eye_enlarge_ratio: 1.4\n",
      "      use_shuffle: False\n",
      "      num_worker_per_gpu: 6\n",
      "      batch_size_per_gpu: 8\n",
      "      dataset_enlarge_ratio: 1\n",
      "      prefetch_mode: None\n",
      "      phase: train\n",
      "    ]\n",
      "  ]\n",
      "  network_g:[\n",
      "    type: GFPGANv1\n",
      "    out_size: 512\n",
      "    num_style_feat: 512\n",
      "    channel_multiplier: 1\n",
      "    resample_kernel: [1, 3, 3, 1]\n",
      "    decoder_load_path: experiments/pretrained_models/StyleGAN2_512_Cmul1_FFHQ_B12G4_scratch_800k.pth\n",
      "    fix_decoder: True\n",
      "    num_mlp: 8\n",
      "    lr_mlp: 0.01\n",
      "    input_is_latent: True\n",
      "    different_w: True\n",
      "    narrow: 1\n",
      "    sft_half: True\n",
      "  ]\n",
      "  network_d:[\n",
      "    type: StyleGAN2Discriminator\n",
      "    out_size: 512\n",
      "    channel_multiplier: 1\n",
      "    resample_kernel: [1, 3, 3, 1]\n",
      "  ]\n",
      "  network_d_left_eye:[\n",
      "    type: FacialComponentDiscriminator\n",
      "  ]\n",
      "  network_d_right_eye:[\n",
      "    type: FacialComponentDiscriminator\n",
      "  ]\n",
      "  network_d_mouth:[\n",
      "    type: FacialComponentDiscriminator\n",
      "  ]\n",
      "  network_identity:[\n",
      "    type: ResNetArcFace\n",
      "    block: IRBlock\n",
      "    layers: [2, 2, 2, 2]\n",
      "    use_se: False\n",
      "  ]\n",
      "  path:[\n",
      "    pretrain_network_g: experiments/pretrained_models/GFPGANv1.pth\n",
      "    param_key_g: params_ema\n",
      "    strict_load_g: None\n",
      "    pretrain_network_d: experiments/pretrained_models/GFPGANv1_net_d.pth\n",
      "    pretrain_network_d_left_eye: experiments/pretrained_models/GFPGANv1_net_d_left_eye.pth\n",
      "    pretrain_network_d_right_eye: experiments/pretrained_models/GFPGANv1_net_d_right_eye.pth\n",
      "    pretrain_network_d_mouth: experiments/pretrained_models/GFPGANv1_net_d_mouth.pth\n",
      "    pretrain_network_identity: experiments/pretrained_models/arcface_resnet18.pth\n",
      "    resume_state: None\n",
      "    ignore_resume_networks: ['network_identity']\n",
      "    experiments_root: /media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512\n",
      "    models: /media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512/models\n",
      "    training_states: /media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512/training_states\n",
      "    log: /media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512\n",
      "    visualization: /media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo/experiments/train_GFPGANv1_512/visualization\n",
      "  ]\n",
      "  train:[\n",
      "    optim_g:[\n",
      "      type: Adam\n",
      "      lr: 0.002\n",
      "    ]\n",
      "    optim_d:[\n",
      "      type: Adam\n",
      "      lr: 0.002\n",
      "    ]\n",
      "    optim_component:[\n",
      "      type: Adam\n",
      "      lr: 0.002\n",
      "    ]\n",
      "    scheduler:[\n",
      "      type: MultiStepLR\n",
      "      milestones: [600000, 700000]\n",
      "      gamma: 0.5\n",
      "    ]\n",
      "    total_iter: 50000\n",
      "    warmup_iter: -1\n",
      "    pixel_opt:[\n",
      "      type: L1Loss\n",
      "      loss_weight: 0.1\n",
      "      reduction: mean\n",
      "    ]\n",
      "    L1_opt:[\n",
      "      type: L1Loss\n",
      "      loss_weight: 1\n",
      "      reduction: mean\n",
      "    ]\n",
      "    pyramid_loss_weight: 1\n",
      "    remove_pyramid_loss: 50000\n",
      "    perceptual_opt:[\n",
      "      type: PerceptualLoss\n",
      "      layer_weights:[\n",
      "        conv1_2: 0.1\n",
      "        conv2_2: 0.1\n",
      "        conv3_4: 1\n",
      "        conv4_4: 1\n",
      "        conv5_4: 1\n",
      "      ]\n",
      "      vgg_type: vgg19\n",
      "      use_input_norm: True\n",
      "      perceptual_weight: 1.0\n",
      "      style_weight: 50\n",
      "      range_norm: True\n",
      "      criterion: l1\n",
      "    ]\n",
      "    gan_opt:[\n",
      "      type: GANLoss\n",
      "      gan_type: wgan_softplus\n",
      "      loss_weight: 0.1\n",
      "    ]\n",
      "    r1_reg_weight: 10\n",
      "    gan_component_opt:[\n",
      "      type: GANLoss\n",
      "      gan_type: vanilla\n",
      "      real_label_val: 1.0\n",
      "      fake_label_val: 0.0\n",
      "      loss_weight: 1.0\n",
      "    ]\n",
      "    comp_style_weight: 200\n",
      "    identity_weight: 10\n",
      "    net_d_iters: 1\n",
      "    net_d_init_iters: 0\n",
      "    net_d_reg_every: 16\n",
      "  ]\n",
      "  val:[\n",
      "    val_freq: 5000.0\n",
      "    save_img: True\n",
      "    metrics:[\n",
      "      psnr:[\n",
      "        type: calculate_psnr\n",
      "        crop_border: 0\n",
      "        test_y_channel: False\n",
      "      ]\n",
      "    ]\n",
      "  ]\n",
      "  logger:[\n",
      "    print_freq: 1000\n",
      "    save_checkpoint_freq: 5000.0\n",
      "    use_tb_logger: True\n",
      "    wandb:[\n",
      "      project: None\n",
      "      resume_id: None\n",
      "    ]\n",
      "  ]\n",
      "  dist_params:[\n",
      "    backend: nccl\n",
      "    port: 29500\n",
      "  ]\n",
      "  find_unused_parameters: True\n",
      "  dist: False\n",
      "  rank: 0\n",
      "  world_size: 1\n",
      "  auto_resume: False\n",
      "  is_train: True\n",
      "  root_path: /media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo\n",
      "\n",
      "2022-05-02 15:06:27,246 INFO: Blur: blur_kernel_size 41, sigma: [0.1, 10]\n",
      "2022-05-02 15:06:27,248 INFO: Downsample: downsample_range [0.8, 8]\n",
      "2022-05-02 15:06:27,249 INFO: Noise: [0, 20]\n",
      "2022-05-02 15:06:27,250 INFO: JPEG compression: [60, 100]\n",
      "2022-05-02 15:06:27,250 INFO: Use random color jitter. Prob: 0.3, shift: 20\n",
      "2022-05-02 15:06:27,251 INFO: Use random gray. Prob: 0.01\n",
      "2022-05-02 15:06:27,251 INFO: Dataset [FFHQDegradationDataset] - FFHQ is built.\n",
      "2022-05-02 15:06:27,297 INFO: Training statistics:\n",
      "\tNumber of train images: 223218\n",
      "\tDataset enlarge ratio: 1\n",
      "\tBatch size per gpu: 8\n",
      "\tWorld size (gpu number): 1\n",
      "\tRequire iter number per epoch: 27903\n",
      "\tTotal epochs: 2; iters: 50000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= BATCH SIZE\n",
      "8\n",
      "###### out_size512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:06:30,452 INFO: Network [GFPGANv1] is created.\n",
      "2022-05-02 15:06:30,554 INFO: Network: GFPGANv1, with parameters: 78,308,493\n",
      "2022-05-02 15:06:30,554 INFO: GFPGANv1(\n",
      "  (conv_body_first): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=3, out_channels=16, kernel_size=1, stride=1, padding=0, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv_body_down): ModuleList(\n",
      "    (0): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=16, out_channels=32, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=32, out_channels=64, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=64, out_channels=128, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=128, out_channels=256, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=256, out_channels=256, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=256, out_channels=256, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=256, out_channels=256, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv_body_up): ModuleList(\n",
      "    (0): ResUpBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvUpLayer(\n",
      "        (activation): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvUpLayer()\n",
      "    )\n",
      "    (1): ResUpBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvUpLayer(\n",
      "        (activation): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvUpLayer()\n",
      "    )\n",
      "    (2): ResUpBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvUpLayer(\n",
      "        (activation): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvUpLayer()\n",
      "    )\n",
      "    (3): ResUpBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvUpLayer(\n",
      "        (activation): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvUpLayer()\n",
      "    )\n",
      "    (4): ResUpBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvUpLayer(\n",
      "        (activation): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvUpLayer()\n",
      "    )\n",
      "    (5): ResUpBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvUpLayer(\n",
      "        (activation): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvUpLayer()\n",
      "    )\n",
      "    (6): ResUpBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvUpLayer(\n",
      "        (activation): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvUpLayer()\n",
      "    )\n",
      "  )\n",
      "  (toRGB): ModuleList(\n",
      "    (0): EqualConv2d(in_channels=256, out_channels=3, kernel_size=1, stride=1, padding=0, bias=True)\n",
      "    (1): EqualConv2d(in_channels=256, out_channels=3, kernel_size=1, stride=1, padding=0, bias=True)\n",
      "    (2): EqualConv2d(in_channels=256, out_channels=3, kernel_size=1, stride=1, padding=0, bias=True)\n",
      "    (3): EqualConv2d(in_channels=128, out_channels=3, kernel_size=1, stride=1, padding=0, bias=True)\n",
      "    (4): EqualConv2d(in_channels=64, out_channels=3, kernel_size=1, stride=1, padding=0, bias=True)\n",
      "    (5): EqualConv2d(in_channels=32, out_channels=3, kernel_size=1, stride=1, padding=0, bias=True)\n",
      "    (6): EqualConv2d(in_channels=16, out_channels=3, kernel_size=1, stride=1, padding=0, bias=True)\n",
      "  )\n",
      "  (final_linear): EqualLinear(in_channels=4096, out_channels=8192, bias=True)\n",
      "  (style_lstm): LSTM(512, 512)\n",
      "  (stylegan_decoder): StyleGAN2GeneratorSFT(\n",
      "    (style_mlp): Sequential(\n",
      "      (0): NormStyleCode()\n",
      "      (1): EqualLinear(in_channels=512, out_channels=512, bias=True)\n",
      "      (2): EqualLinear(in_channels=512, out_channels=512, bias=True)\n",
      "      (3): EqualLinear(in_channels=512, out_channels=512, bias=True)\n",
      "      (4): EqualLinear(in_channels=512, out_channels=512, bias=True)\n",
      "      (5): EqualLinear(in_channels=512, out_channels=512, bias=True)\n",
      "      (6): EqualLinear(in_channels=512, out_channels=512, bias=True)\n",
      "      (7): EqualLinear(in_channels=512, out_channels=512, bias=True)\n",
      "      (8): EqualLinear(in_channels=512, out_channels=512, bias=True)\n",
      "    )\n",
      "    (constant_input): ConstantInput()\n",
      "    (style_conv1): StyleConv(\n",
      "      (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=512, kernel_size=3, demodulate=True, sample_mode=None)\n",
      "      (activate): FusedLeakyReLU()\n",
      "    )\n",
      "    (to_rgb1): ToRGB(\n",
      "      (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=3, kernel_size=1, demodulate=False, sample_mode=None)\n",
      "    )\n",
      "    (style_convs): ModuleList(\n",
      "      (0): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=512, kernel_size=3, demodulate=True, sample_mode=upsample)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (1): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=512, kernel_size=3, demodulate=True, sample_mode=None)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (2): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=512, kernel_size=3, demodulate=True, sample_mode=upsample)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (3): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=512, kernel_size=3, demodulate=True, sample_mode=None)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (4): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=512, kernel_size=3, demodulate=True, sample_mode=upsample)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (5): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=512, kernel_size=3, demodulate=True, sample_mode=None)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (6): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=256, kernel_size=3, demodulate=True, sample_mode=upsample)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (7): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=256, out_channels=256, kernel_size=3, demodulate=True, sample_mode=None)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (8): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=256, out_channels=128, kernel_size=3, demodulate=True, sample_mode=upsample)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (9): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=128, out_channels=128, kernel_size=3, demodulate=True, sample_mode=None)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (10): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=128, out_channels=64, kernel_size=3, demodulate=True, sample_mode=upsample)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (11): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=64, out_channels=64, kernel_size=3, demodulate=True, sample_mode=None)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (12): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=64, out_channels=32, kernel_size=3, demodulate=True, sample_mode=upsample)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "      (13): StyleConv(\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=32, out_channels=32, kernel_size=3, demodulate=True, sample_mode=None)\n",
      "        (activate): FusedLeakyReLU()\n",
      "      )\n",
      "    )\n",
      "    (to_rgbs): ModuleList(\n",
      "      (0): ToRGB(\n",
      "        (upsample): UpFirDnUpsample(factor=2)\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=3, kernel_size=1, demodulate=False, sample_mode=None)\n",
      "      )\n",
      "      (1): ToRGB(\n",
      "        (upsample): UpFirDnUpsample(factor=2)\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=3, kernel_size=1, demodulate=False, sample_mode=None)\n",
      "      )\n",
      "      (2): ToRGB(\n",
      "        (upsample): UpFirDnUpsample(factor=2)\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=512, out_channels=3, kernel_size=1, demodulate=False, sample_mode=None)\n",
      "      )\n",
      "      (3): ToRGB(\n",
      "        (upsample): UpFirDnUpsample(factor=2)\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=256, out_channels=3, kernel_size=1, demodulate=False, sample_mode=None)\n",
      "      )\n",
      "      (4): ToRGB(\n",
      "        (upsample): UpFirDnUpsample(factor=2)\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=128, out_channels=3, kernel_size=1, demodulate=False, sample_mode=None)\n",
      "      )\n",
      "      (5): ToRGB(\n",
      "        (upsample): UpFirDnUpsample(factor=2)\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=64, out_channels=3, kernel_size=1, demodulate=False, sample_mode=None)\n",
      "      )\n",
      "      (6): ToRGB(\n",
      "        (upsample): UpFirDnUpsample(factor=2)\n",
      "        (modulated_conv): ModulatedConv2d(in_channels=32, out_channels=3, kernel_size=1, demodulate=False, sample_mode=None)\n",
      "      )\n",
      "    )\n",
      "    (noises): Module()\n",
      "  )\n",
      "  (condition_scale): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): EqualConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): EqualConv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): EqualConv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (condition_shift): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): EqualConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): EqualConv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): EqualConv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "      (1): ScaledLeakyReLU()\n",
      "      (2): EqualConv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:06:30,894 INFO: Loading GFPGANv1 model from experiments/pretrained_models/GFPGANv1.pth, with param key: [params_ema].\n",
      "2022-05-02 15:06:30,962 WARNING: Current net - loaded net:\n",
      "2022-05-02 15:06:30,963 WARNING:   lstm_fusion_param\n",
      "2022-05-02 15:06:30,963 WARNING:   style_lstm.bias_hh_l0\n",
      "2022-05-02 15:06:30,964 WARNING:   style_lstm.bias_ih_l0\n",
      "2022-05-02 15:06:30,964 WARNING:   style_lstm.weight_hh_l0\n",
      "2022-05-02 15:06:30,964 WARNING:   style_lstm.weight_ih_l0\n",
      "2022-05-02 15:06:30,964 WARNING: Loaded net - current net:\n",
      "2022-05-02 15:06:31,189 INFO: Network [StyleGAN2Discriminator] is created.\n",
      "2022-05-02 15:06:31,216 INFO: Network: StyleGAN2Discriminator, with parameters: 24,030,753\n",
      "2022-05-02 15:06:31,217 INFO: StyleGAN2Discriminator(\n",
      "  (conv_body): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (0): EqualConv2d(in_channels=3, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False)\n",
      "      (1): FusedLeakyReLU()\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=32, out_channels=64, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=64, out_channels=128, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=128, out_channels=256, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=256, out_channels=512, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=512, out_channels=512, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=512, out_channels=512, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      (conv1): ConvLayer(\n",
      "        (0): EqualConv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "        (1): FusedLeakyReLU()\n",
      "      )\n",
      "      (conv2): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "        (2): FusedLeakyReLU()\n",
      "      )\n",
      "      (skip): ConvLayer(\n",
      "        (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "        (1): EqualConv2d(in_channels=512, out_channels=512, kernel_size=1, stride=2, padding=0, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=513, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (final_linear): Sequential(\n",
      "    (0): EqualLinear(in_channels=8192, out_channels=512, bias=True)\n",
      "    (1): EqualLinear(in_channels=512, out_channels=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2022-05-02 15:06:31,253 INFO: Loading StyleGAN2Discriminator model from experiments/pretrained_models/GFPGANv1_net_d.pth, with param key: [params].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### out_size512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:06:31,897 INFO: Network [GFPGANv1] is created.\n",
      "2022-05-02 15:06:32,309 INFO: Loading GFPGANv1 model from experiments/pretrained_models/GFPGANv1.pth, with param key: [params_ema].\n",
      "2022-05-02 15:06:32,375 WARNING: Current net - loaded net:\n",
      "2022-05-02 15:06:32,375 WARNING:   lstm_fusion_param\n",
      "2022-05-02 15:06:32,376 WARNING:   style_lstm.bias_hh_l0\n",
      "2022-05-02 15:06:32,376 WARNING:   style_lstm.bias_ih_l0\n",
      "2022-05-02 15:06:32,376 WARNING:   style_lstm.weight_hh_l0\n",
      "2022-05-02 15:06:32,376 WARNING:   style_lstm.weight_ih_l0\n",
      "2022-05-02 15:06:32,377 WARNING: Loaded net - current net:\n",
      "2022-05-02 15:06:32,487 INFO: Network [FacialComponentDiscriminator] is created.\n",
      "2022-05-02 15:06:32,490 INFO: Network: FacialComponentDiscriminator, with parameters: 1,110,785\n",
      "2022-05-02 15:06:32,490 INFO: FacialComponentDiscriminator(\n",
      "  (conv1): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv2): ConvLayer(\n",
      "    (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "    (1): EqualConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "    (2): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv3): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv4): ConvLayer(\n",
      "    (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "    (1): EqualConv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "    (2): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv5): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (final_conv): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=256, out_channels=1, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2022-05-02 15:06:32,493 INFO: Loading FacialComponentDiscriminator model from experiments/pretrained_models/GFPGANv1_net_d_left_eye.pth, with param key: [params].\n",
      "2022-05-02 15:06:32,504 INFO: Network [FacialComponentDiscriminator] is created.\n",
      "2022-05-02 15:06:32,507 INFO: Network: FacialComponentDiscriminator, with parameters: 1,110,785\n",
      "2022-05-02 15:06:32,507 INFO: FacialComponentDiscriminator(\n",
      "  (conv1): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv2): ConvLayer(\n",
      "    (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "    (1): EqualConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "    (2): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv3): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv4): ConvLayer(\n",
      "    (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "    (1): EqualConv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "    (2): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv5): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (final_conv): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=256, out_channels=1, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2022-05-02 15:06:32,509 INFO: Loading FacialComponentDiscriminator model from experiments/pretrained_models/GFPGANv1_net_d_right_eye.pth, with param key: [params].\n",
      "2022-05-02 15:06:32,519 INFO: Network [FacialComponentDiscriminator] is created.\n",
      "2022-05-02 15:06:32,521 INFO: Network: FacialComponentDiscriminator, with parameters: 1,110,785\n",
      "2022-05-02 15:06:32,522 INFO: FacialComponentDiscriminator(\n",
      "  (conv1): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv2): ConvLayer(\n",
      "    (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "    (1): EqualConv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "    (2): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv3): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv4): ConvLayer(\n",
      "    (0): UpFirDnSmooth(upsample_factor=1, downsample_factor=2)\n",
      "    (1): EqualConv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=0, bias=False)\n",
      "    (2): FusedLeakyReLU()\n",
      "  )\n",
      "  (conv5): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
      "    (1): FusedLeakyReLU()\n",
      "  )\n",
      "  (final_conv): ConvLayer(\n",
      "    (0): EqualConv2d(in_channels=256, out_channels=1, kernel_size=3, stride=1, padding=1, bias=True)\n",
      "  )\n",
      ")\n",
      "2022-05-02 15:06:32,523 INFO: Loading FacialComponentDiscriminator model from experiments/pretrained_models/GFPGANv1_net_d_mouth.pth, with param key: [params].\n",
      "2022-05-02 15:06:32,527 INFO: Loss [GANLoss] is created.\n",
      "2022-05-02 15:06:32,528 INFO: Loss [L1Loss] is created.\n",
      "2022-05-02 15:06:33,898 INFO: Loss [PerceptualLoss] is created.\n",
      "2022-05-02 15:06:33,920 INFO: Loss [L1Loss] is created.\n",
      "2022-05-02 15:06:33,921 INFO: Loss [GANLoss] is created.\n",
      "2022-05-02 15:06:34,189 INFO: Network [ResNetArcFace] is created.\n",
      "2022-05-02 15:06:34,220 INFO: Network: ResNetArcFace, with parameters: 25,627,081\n",
      "2022-05-02 15:06:34,221 INFO: ResNetArcFace(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (prelu): PReLU(num_parameters=1)\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): IRBlock(\n",
      "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): IRBlock(\n",
      "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): IRBlock(\n",
      "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): IRBlock(\n",
      "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): IRBlock(\n",
      "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): IRBlock(\n",
      "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): IRBlock(\n",
      "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): IRBlock(\n",
      "      (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (prelu): PReLU(num_parameters=1)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc5): Linear(in_features=32768, out_features=512, bias=True)\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:06:34,275 INFO: Loading ResNetArcFace model from experiments/pretrained_models/arcface_resnet18.pth, with param key: [None].\n",
      "2022-05-02 15:06:34,301 WARNING: Current net - loaded net:\n",
      "2022-05-02 15:06:34,301 WARNING:   bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,302 WARNING:   bn4.num_batches_tracked\n",
      "2022-05-02 15:06:34,302 WARNING:   bn5.num_batches_tracked\n",
      "2022-05-02 15:06:34,302 WARNING:   layer1.0.bn0.num_batches_tracked\n",
      "2022-05-02 15:06:34,303 WARNING:   layer1.0.bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,303 WARNING:   layer1.0.bn2.num_batches_tracked\n",
      "2022-05-02 15:06:34,303 WARNING:   layer1.1.bn0.num_batches_tracked\n",
      "2022-05-02 15:06:34,303 WARNING:   layer1.1.bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,304 WARNING:   layer1.1.bn2.num_batches_tracked\n",
      "2022-05-02 15:06:34,304 WARNING:   layer2.0.bn0.num_batches_tracked\n",
      "2022-05-02 15:06:34,304 WARNING:   layer2.0.bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,304 WARNING:   layer2.0.bn2.num_batches_tracked\n",
      "2022-05-02 15:06:34,304 WARNING:   layer2.0.downsample.1.num_batches_tracked\n",
      "2022-05-02 15:06:34,305 WARNING:   layer2.1.bn0.num_batches_tracked\n",
      "2022-05-02 15:06:34,305 WARNING:   layer2.1.bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,305 WARNING:   layer2.1.bn2.num_batches_tracked\n",
      "2022-05-02 15:06:34,305 WARNING:   layer3.0.bn0.num_batches_tracked\n",
      "2022-05-02 15:06:34,306 WARNING:   layer3.0.bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,306 WARNING:   layer3.0.bn2.num_batches_tracked\n",
      "2022-05-02 15:06:34,306 WARNING:   layer3.0.downsample.1.num_batches_tracked\n",
      "2022-05-02 15:06:34,306 WARNING:   layer3.1.bn0.num_batches_tracked\n",
      "2022-05-02 15:06:34,306 WARNING:   layer3.1.bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,307 WARNING:   layer3.1.bn2.num_batches_tracked\n",
      "2022-05-02 15:06:34,307 WARNING:   layer4.0.bn0.num_batches_tracked\n",
      "2022-05-02 15:06:34,307 WARNING:   layer4.0.bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,307 WARNING:   layer4.0.bn2.num_batches_tracked\n",
      "2022-05-02 15:06:34,308 WARNING:   layer4.0.downsample.1.num_batches_tracked\n",
      "2022-05-02 15:06:34,308 WARNING:   layer4.1.bn0.num_batches_tracked\n",
      "2022-05-02 15:06:34,308 WARNING:   layer4.1.bn1.num_batches_tracked\n",
      "2022-05-02 15:06:34,308 WARNING:   layer4.1.bn2.num_batches_tracked\n",
      "2022-05-02 15:06:34,309 WARNING: Loaded net - current net:\n",
      "2022-05-02 15:06:34,343 INFO: Model [GFPGANModel] is created.\n"
     ]
    }
   ],
   "source": [
    "root_path = '/media/server_admin/890419dd-5419-4fdf-ae01-37ee1e1a2185/raj_gfpgan/repo'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "resume_state = load_resume_state(opt)\n",
    "# mkdir for experiments and logger\n",
    "if resume_state is None:\n",
    "  make_exp_dirs(opt)\n",
    "  if opt['logger'].get('use_tb_logger') and 'debug' not in opt['name'] and opt['rank'] == 0:\n",
    "    mkdir_and_rename(osp.join(opt['root_path'], 'tb_logger', opt['name']))\n",
    "\n",
    "\n",
    "log_file = osp.join(opt['path']['log'], f\"train_{opt['name']}_{get_time_str()}.log\")\n",
    "logger = get_root_logger(logger_name='basicsr', log_level=logging.INFO, log_file=log_file)\n",
    "logger.info(get_env_info())\n",
    "logger.info(dict2str(opt))\n",
    "# initialize wandb and tb loggers\n",
    "tb_logger = init_tb_loggers(opt)\n",
    "\n",
    "# create train and validation dataloaders\n",
    "result = create_train_val_dataloader(opt, logger)\n",
    "train_loader, train_sampler, val_loaders, total_epochs, total_iters = result\n",
    "\n",
    "model = build_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(total_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xcdl-zGnxzuG",
    "outputId": "3d008c8c-8037-4773-b8c6-1d1ce2027af0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 15:06:34,600 INFO: Start training from epoch: 0, iter: 0\n"
     ]
    }
   ],
   "source": [
    "if resume_state:  # resume training\n",
    "  model.resume_training(resume_state)  # handle optimizers and schedulers\n",
    "  logger.info(f\"Resuming training from epoch: {resume_state['epoch']}, \" f\"iter: {resume_state['iter']}.\")\n",
    "  start_epoch = resume_state['epoch']\n",
    "  current_iter = resume_state['iter']\n",
    "else:\n",
    "  start_epoch = 0\n",
    "  current_iter = 0\n",
    "\n",
    "msg_logger = MessageLogger(opt, current_iter, tb_logger)\n",
    "\n",
    "prefetch_mode = opt['datasets']['train'].get('prefetch_mode')\n",
    "if prefetch_mode is None or prefetch_mode == 'cpu':\n",
    "  prefetcher = CPUPrefetcher(train_loader)\n",
    "elif prefetch_mode == 'cuda':\n",
    "  prefetcher = CUDAPrefetcher(train_loader, opt)\n",
    "  logger.info(f'Use {prefetch_mode} prefetch dataloader')\n",
    "  if opt['datasets']['train'].get('pin_memory') is not True:\n",
    "      raise ValueError('Please set pin_memory=True for CUDAPrefetcher.')\n",
    "else:\n",
    "  raise ValueError(f'Wrong prefetch_mode {prefetch_mode}')\n",
    "\n",
    "logger.info(f'Start training from epoch: {start_epoch}, iter: {current_iter}')\n",
    "data_timer, iter_timer = AvgTimer(), AvgTimer()\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, total_epochs + 1):\n",
    "  train_sampler.set_epoch(epoch)\n",
    "  prefetcher.reset()\n",
    "  train_data = prefetcher.next()\n",
    "\n",
    "  while train_data is not None:\n",
    "#     print('iter')\n",
    "    data_timer.record()\n",
    "\n",
    "    current_iter += 1\n",
    "    if current_iter > total_iters:\n",
    "      break\n",
    "    # update learning rate\n",
    "    model.update_learning_rate(current_iter, warmup_iter=opt['train'].get('warmup_iter', -1))\n",
    "    # training\n",
    "    model.feed_data(train_data)\n",
    "    model.optimize_parameters(current_iter)\n",
    "    iter_timer.record()\n",
    "    if current_iter == 1:\n",
    "      # reset start time in msg_logger for more accurate eta_time\n",
    "      # not work in resume mode\n",
    "      msg_logger.reset_start_time()\n",
    "    # log\n",
    "    if current_iter % opt['logger']['print_freq'] == 0:\n",
    "      log_vars = {'epoch': epoch, 'iter': current_iter}\n",
    "      log_vars.update({'lrs': model.get_current_learning_rate()})\n",
    "      log_vars.update({'time': iter_timer.get_avg_time(), 'data_time': data_timer.get_avg_time()})\n",
    "      log_vars.update(model.get_current_log())\n",
    "      msg_logger(log_vars)\n",
    "\n",
    "    # save models and training states\n",
    "    if current_iter % opt['logger']['save_checkpoint_freq'] == 0:\n",
    "      logger.info('Saving models and training states.')\n",
    "      model.save(epoch, current_iter)\n",
    "\n",
    "    # validation\n",
    "    if opt.get('val') is not None and (current_iter % opt['val']['val_freq'] == 0):\n",
    "      if len(val_loaders) > 1:\n",
    "        logger.warning('Multiple validation datasets are *only* supported by SRModel.')\n",
    "      for val_loader in val_loaders:\n",
    "        model.validation(val_loader, current_iter, tb_logger, opt['val']['save_img'])\n",
    "\n",
    "    data_timer.start()\n",
    "    iter_timer.start()\n",
    "    train_data = prefetcher.next()\n",
    "    # end of iter\n",
    "\n",
    "# end of epoch\n",
    "e\n",
    "consumed_time = str(datetime.timedelta(seconds=int(time.time() - start_time)))\n",
    "logger.info(f'End of training. Time consumed: {consumed_time}')\n",
    "logger.info('Save the latest model.')\n",
    "model.save(epoch=-1, current_iter=-1)  # -1 stands for the latest\n",
    "\n",
    "if tb_logger:\n",
    "  tb_logger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnm3brzK4He8",
    "outputId": "4974b7ae-21fe-4459-cab2-ce52140f65c4"
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MDOc3f4b2a0",
    "outputId": "1452a14b-310e-4238-d1af-ae75c91602af"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPrbJVWb3jgy"
   },
   "outputs": [],
   "source": [
    "# from gfpgan.data.ffhq_degradation_dataset import FFHQDegradationDataset\n",
    "\n",
    "# option_train_dataset = options['dataset']['train']\n",
    "\n",
    "# dataset = FFHQDegradationDataset(option_train_dataset)\n",
    "# dataset_enlarge_ratio = option_train_dataset['dataset_enlarge_ratio']\n",
    "\n",
    "# train_sampler = EnlargedSampler(train_set, train_data_opts['world_size'], train_data_opts['rank'], dataset_enlarge_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IV8BwWujYRda"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "\n",
    "# for img_path in os.listdir('./ffhq_small'):\n",
    "#   print(img_path)\n",
    "#   img = cv2.imread('./ffhq_small/' + img_path)\n",
    "#   img_512 = cv2.resize(img, (512, 512))\n",
    "#   cv2.imwrite('./ffhq_small_512/' + img_path, img_512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Yetfl1LYRYO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6AmNeOwYRV1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WShEPd1nYRSz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8IGZT8T0YRNx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-8JxpPwg4Xz"
   },
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "CdMZYp0T7NAy",
    "outputId": "b5da46f9-275d-4378-da33-8fe80d097208"
   },
   "outputs": [],
   "source": [
    "# upload your own images\n",
    "import os\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "upload_folder = 'inputs/upload'\n",
    "\n",
    "if os.path.isdir(upload_folder):\n",
    "    shutil.rmtree(upload_folder)\n",
    "os.mkdir(upload_folder)\n",
    "\n",
    "# upload images\n",
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "  dst_path = os.path.join(upload_folder, filename)\n",
    "  print(f'move {filename} to {dst_path}')\n",
    "  shutil.move(filename, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "FzbDGqQES8LZ",
    "outputId": "ea95c29c-6548-4392-9886-471fd7ada0cf"
   },
   "outputs": [],
   "source": [
    "# !pwd\n",
    "# %cd $drive_path\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGHc73Up70ZA"
   },
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lmQVC3s97z4z"
   },
   "outputs": [],
   "source": [
    "# Now we use the GFPGAN to restore the above low-quality images\n",
    "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
    "!rm -rf results\n",
    "!python inference_gfpgan.py --upscale 2 --test_path inputs/upload --save_root results --model_path experiments/pretrained_models/GFPGANCleanv1-NoCE-C2.pth --bg_upsampler none --only_center_face\n",
    "\n",
    "!ls results/cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkF8VAiF7-PY"
   },
   "source": [
    "## 4. Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "tIeL_NJO8A3B",
    "outputId": "48ade447-72fa-49a4-f976-f4fe9959f681"
   },
   "outputs": [],
   "source": [
    "# We first visualize the cropped faces\n",
    "# The left are the inputs images; the right are the results of GFPGAN\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "def display(img1, img2):\n",
    "  fig = plt.figure(figsize=(25, 10))\n",
    "  ax1 = fig.add_subplot(1, 2, 1) \n",
    "  plt.title('Input image', fontsize=16)\n",
    "  ax1.axis('off')\n",
    "  ax2 = fig.add_subplot(1, 2, 2)\n",
    "  plt.title('GFPGAN output', fontsize=16)\n",
    "  ax2.axis('off')\n",
    "  ax1.imshow(img1)\n",
    "  ax2.imshow(img2)\n",
    "def imread(img_path):\n",
    "  img = cv2.imread(img_path)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img\n",
    "\n",
    "# display each image in the upload folder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "input_folder = 'results/cropped_faces'\n",
    "result_folder = 'results/restored_faces'\n",
    "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
    "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
    "for input_path, output_path in zip(input_list, output_list):\n",
    "  img_input = imread(input_path)\n",
    "  img_output = imread(output_path)\n",
    "  display(img_input, img_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "Jn_2ylqP9qXY",
    "outputId": "12b98342-720d-462b-8670-2f99d29aed8a"
   },
   "outputs": [],
   "source": [
    "# We then visualize the whole image\n",
    "# The left are the inputs images; the right are the results of GFPGAN\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "def display(img1, img2):\n",
    "  fig = plt.figure(figsize=(25, 10))\n",
    "  ax1 = fig.add_subplot(1, 2, 1) \n",
    "  plt.title('Input image', fontsize=16)\n",
    "  ax1.axis('off')\n",
    "  ax2 = fig.add_subplot(1, 2, 2)\n",
    "  plt.title('GFPGAN output', fontsize=16)\n",
    "  ax2.axis('off')\n",
    "  ax1.imshow(img1)\n",
    "  ax2.imshow(img2)\n",
    "def imread(img_path):\n",
    "  img = cv2.imread(img_path)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img\n",
    "\n",
    "# display each image in the upload folder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "input_folder = 'inputs/upload'\n",
    "result_folder = 'results/restored_imgs'\n",
    "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
    "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
    "for input_path, output_path in zip(input_list, output_list):\n",
    "  img_input = imread(input_path)\n",
    "  img_output = imread(output_path)\n",
    "  display(img_input, img_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HR7VEBEb8slX"
   },
   "source": [
    "## 5. Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "zuBCgeH08tdn",
    "outputId": "796a84bd-94c0-4272-db60-b4ee7bd33d6a"
   },
   "outputs": [],
   "source": [
    "# download the result\n",
    "!ls results\n",
    "print('Download results')\n",
    "os.system('zip -r download.zip results')\n",
    "files.download(\"download.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AY1E-ptK0DlM"
   },
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MyGFPGAN_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
